<!DOCTYPE html>
<html lang="en">
  <head>
        <meta charset="UTF-8">
        <link rel="stylesheet" href="main.css">
        <!-- <link rel="icon" type="image/x-icon" href="assets/digit.png"> -->
        <title>Bipedal-STL</title>

        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
  </head>
  <body>


    <div id="title_slide">
        <div class="title_left">
            <h1>Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Locomotion using Benders Decomposition
            </h1>
        

            <!-- <div class="box alt">
              <div class="row uniform">
                <div class="2u"><a href="https://www.linkedin.com/in/jiming-ren/">                   <span class="image fit"><img src="assets/author_photo/jiming.jpg" alt="Jiming Ren" /></span>Jiming Ren</a></div>
                <div class="2u"><a href="https://xuanlin.github.io/XuanLin-X/">                      <span class="image fit"><img src="assets/author_photo/xuan.jpg" alt="Xuan Lin" /></span>Xuan Lin</a></div>
                <div class="2u"><a href="https://mineyev2.github.io/roman_mineyev/">              <span class="image fit"><img src="assets/author_photo/roman.jpg" alt="Roman Mineyev" /></span>Roman Mineyev</a></div>
                <div class="2u"><a href="https://research.gatech.edu/people/karen-m-feigh">                 <span class="image fit"><img src="assets/author_photo/karen_feigh.jpg" alt="Karen Feigh" /></span>Karen Feigh</a></div>
                <div class="2u"><a href="https://research.gatech.edu/people/samuel-coogan">                 <span class="image fit"><img src="assets/author_photo/samuel_coogan.jpg" alt="Samuel Coogan" /></span>Samuel Coogan</a></div>
                <div class="2u"><a href="https://research.gatech.edu/people/ye-zhao">                 <span class="image fit"><img src="assets/author_photo/ye.jpg" alt="Ye Zhao" /></span>Ye Zhao</a></div>
              </div>
            </div> -->

            <div class="gatech">
                <p>Georgia Institute of Technology</p>
            </div>
            <!-- <div class="button-container">
                <a href="" class="button">Paper</a>
            </div> --> 

            <br>
            <br>

            <div class="main_img">
                <img src="assets/figures/pitch.jpg" alt="Timelapse of four task specifications" max-width: 30%>
            </div>
            
            <br>
            <div id="abstract" class="grid-container">
                <p>
                    Task and motion planning under Signal Temporal Logic constraints is known to be NP-hard.
                    A common class of approaches formulates these hybrid problems, which involve discrete task scheduling
                    and continuous motion planning, as mixed-integer programs (MIP).
                    <!-- <br><br> -->
                    However, in applications for bipedal locomotion, introduction of non-convex constraints such as
                    kinematic reachability and footstep rotation exacerbates computational complexity of MIPs.
                    In this work, we present a method based on Benders Decomposition to address this challenge
                    where solving the entire monolithic optimization problem can be prohibitively intractable.
                    <!-- <br><br> -->
                    Benders Decomposition proposes an iterative cutting-plane technique that partitions the problem
                    into a master problem to prototype a plan that meets the task specification, and a series of subproblems
                    for kinematics and dynamics feasibility checks.
                    <!-- <br><br> -->
                    Our experiments demonstrate that this method achieves faster planning compared to alternative algorithms
                    for solving the resulting optimization program with nonlinear constraints.
                </p>
            </div>
        </div>
    </div>
    <hr class="rounded">
    
    <!-- Completed till here so far -->

    <div id="overview">

        <h1>Benchmark Scenarios</h1>

        <p>
            <!-- TODO: Write some more detail in the beginning, because in the website there's no detailing about why we need these benchmarks, etc. -->
            Our benchmark environments cover a range of application scenarios in which the robot is tasked to access a number of 
            PoIs subject to certain logical and temporal conditions. Some of these environments are adapted from prior works, 
            but we extend the planning horizon to accommodate finer time discretization for footsteps and more complex task specifications. 
            Below, we present four benchmark scenarios, each with a unique task specification and a corresponding video demonstration.
        </p>

        <div class="allegroupper">
            <img src="assets/benchmark_scenarios/timelapse.jpg" alt="Timelapse of four task specifications">
        </div>

        <h2>1. Delivery Environment</h2>
        <p>
            The robot must collect a box from one shelf of each color before it can pass through Region 7 
            and ultimately reach the table to unload at Point 15. The task specification is shown below:
        </p>

        \[ \varphi = \neg \pi^{7} \ \mathcal U_{[0, 70]}\ (\pi^9 \vee \pi^{10}) \wedge \neg \pi^{7} \ \mathcal U_{[0, 70]}\ (\pi^{11} \vee \pi^{13}) \wedge \neg \pi^{7} \ \mathcal U_{[0, 70]}\ (\pi^{12} \vee \pi^{14}) \wedge \Diamond_{[0, 70]} \pi^{15} \]

        <div class="video_container">
            <video autoplay="" muted="" playsinline="" loop="" controls="" preload="metadata">
                        <source src="assets/demo_videos/warehouse_demo.mp4" type="video/mp4">
            </video>
        </div>

        <h2>2. Store Environment</h2>

        <p>
            The robot is instructed to reach one of Points 8, 9, or 10 within 15 steps after the start, 
            and then sequentially reach one of Points 11 or 12, followed by one of Points 13, 14, and finally Point 15.
        </p>

        \[ \varphi = \Diamond_{[0, 15]} (\pi^8 \vee \pi^9 \vee \pi^{10}) \wedge \neg (\pi^{13} \vee \pi^{14}) \ \mathcal U_{[10, 50]}\ (\pi^{11} \vee \pi^{12}) \wedge \neg \pi^{15} \ \mathcal U_{[40, 70]}\ (\pi^{13} \vee \pi^{14}) \wedge \Diamond_{[50, 70]} \pi^{15} \]

        <div class="video_container">
            <video autoplay="" muted="" playsinline="" loop="" controls="" preload="metadata">
                        <source src="assets/demo_videos/store_demo.mp4" type="video/mp4">
            </video>
        </div>

        <h2>3. Door Puzzle Environment</h2>

        <p>
            The robot is required to reach Point 17 at the end which can only be accessed by passing through several doors. 
            Each door is paired with a key that must be collected from a designated PoI. The door-key pairings are outlined in the task specification:
        </p>

        \[ \varphi = \neg \pi^{7} \ \mathcal U_{[0, 130]}\ \pi^{14}  \wedge \neg \pi^{8} \ \mathcal U_{[0, 130]}\ \pi^{12} \wedge \neg \pi^{9} \ \mathcal U_{[0, 130]}\ \pi^{13} \wedge \neg \pi^{11} \ \mathcal U_{[0, 130]}\ \pi^{15} \wedge \neg \pi^{10} \ \mathcal U_{[0, 130]}\ \pi^{16} \wedge \Diamond_{[0, 130]} \pi^{17} \]

        <div class="video_container">
            <video autoplay="" muted="" playsinline="" loop="" controls="" preload="metadata">
                        <source src="assets/demo_videos/doorpuzzle_demo.mp4" type="video/mp4">
            </video>
        </div>

        <h2>4. Factory Environment</h2>

        <p>
            The robot must visit the charging stations at Points 12 and 13 within 50 steps each time it leaves a charging station. 
            Additionally, after retrieving a box from one of the tables at Points 6, 8, 9, or 11, the robot must visit either Point 7 or 10 within 20 steps to unload it onto the shelves.
        </p>

        \[ \varphi = \square_{[0, 130]} \left(\neg (\pi^{12} \vee \pi^{13})\Rightarrow \Diamond_{[0, 50]}(\pi^{12} \vee \pi^{13})\right) \wedge \square_{[0, 130]} \left((\pi^{6}\vee \pi^{8}\vee \pi^{9}\vee \pi^{11}) \Rightarrow\Diamond_{[0, 20]}(\pi^{7} \vee \pi^{10})\right) \wedge \Diamond_{[0, 130]}\pi^6 \wedge \Diamond_{[0, 130]}\pi^8 \wedge \Diamond_{[0, 130]}\pi^9 \wedge \Diamond_{[0, 130]}\pi^{10} \]

        <div class="video_container">
            <video autoplay="" muted="" playsinline="" loop="" controls="" preload="metadata">
                        <source src="assets/demo_videos/rover_demo.mp4" type="video/mp4">
            </video>
        </div>a


        <!--  TODO: Change title to be more exact -->
        <h1> Results and Comparisons </h1>

        <h2> Results </h2>

        <p>
            In the figure below, we show the iterations of solutions generated by our proposed method in the Delivery
            environment. The stripe at the bottom shows the time spent by the BMP
            and the BSPs, along with the number of cuts added to the BMP at the
            end of each iteration. The black stars indicate moments when the BSPs are
            solved as infeasible and multiple feasibility cuts are added, while the yellow
            stars represent iterations when all BSPs are solved as feasible and only an
            optimality cut is added. We highlight three key moments: an infeasible
            solution (A) which is shown as the cyan dots on the top left figure, the first
            feasible solution (B) which is shown by a sequence of LIP models at each
            contact instant on the top left figure, and the optimal solution (C) that is
            represented by a sequence of LIP models at each contact instant on the top
            right figure.
        </p>

        <div class="allegroupper">
            <img src="assets/figures/iteration.png" alt="Timelapse of four task specifications" width="30%">
        </div>

        <p>
            We observe that while the single cut method may not find a feasible solution within 100 iterations, 
            our proposed method is able to consistently find the optimal solution within 20 iterations. 
        </p>

        <h2> Comparisons </h2>
        <p>
            As a baseline for comparison, we solve
            our optimization problem using the well-established decomposition approach ADMM. 
            Our ADMM implementation decomposes the problem into
            an MICP subproblem and an NLP projection step. The constraints
            in the MICP and NLP subproblems are identical to
            those in our BMP and BSP, respectively, except that
            in the NLP, the task schedule is not fixed. Instead,
            ADMM subproblems promote convergence through additional consensus terms in their objective functions that
            penalize deviations between residual variables from other subproblems using L2 norms
            weighted by a penalty parameter. The algorithm alternates between 
            the MICP and NLP steps and updates the
            dual variables until stopping criteria, such as maximum
            residual tolerance or maximum iteration count, are met.
        </p>

        <div class="allegroupper">
            <img src="assets/figures/ADMM.jpg" alt="Timelapse of four task specifications" width="30%">
        </div>
        

        <p>
            The above figure showcases the ADMM convergence for Store environment, showing primal residuals 
            of the position, direction and foothold over iterations. We also 
            compare the result after ADMM hits the threshold and the optimal solution 
            obtained from the BD method in (A) and (B). The Store environment is 
            one of the best convergence scenarios for ADMM among all scenarios.
        </p>

        <p>
            ADMM convergence is non-monotonic, and despite large penalties for consensus violations,
            residuals often remain significant after tens of iterations. This
            indicates that the MICP solution from ADMM does not fully
            satisfy the foot kinematic reachability constraints, and the
            NLP solution does not exactly satisfy the STL constraints.
            In comparison, all the feasible solutions that the BD method
            obtains strictly satisfy all the constraints.
        </p>
        

        <h1>Conclusion</h1>

        <p>
          This work presents a novel distributed approach to accelerate the solving of bipedal TAMP problems under STL 
          specifications using Benders Decomposition. Our approach significantly outperforms baseline methods and has the potential 
          to be extended to other TAMP problems involving different types of robots with varying nonlinear dynamics models. 
          The main bottleneck is that the master problem still accounts for a substantial portion of the total computation 
          time. Future work will focus on improving the efficiency of solving the master problem to further enhance overall performance.
        </p>

        <!-- TODO: BibTex -->
        <!-- <h1>BibTeX</h1> -->
         <!-- <p class="bibtex">
            @article{liu2024opt2skill,<br>
            &nbsp;&nbsp;title={Opt2Skill: Imitating Dynamically-feasible Whole-Body Trajectories for Versatile Humanoid Loco-Manipulation},<br>
            &nbsp;&nbsp;author={Liu, Fukang and Gu, Zhaoyuan and Cai, Yilin and Zhou, Ziyi and Zhao, Shijie and Jung, Hyunyoung and Ha, Sehoon and Chen, Yue and Xu, Danfei and Zhao, Ye},<br>
            &nbsp;&nbsp;journal={arXiv preprint arXiv:2409.20514}<br>
            &nbsp;&nbsp;year={2024},<br>
            }
        </p> -->
       

        <div class="footer">
          <p>This website was developed based on <a href="https://github.com/learning-humanoid-locomotion/learning-humanoid-locomotion.github.io" target="_blank">learning-humanoid-locomotion</a></p>
      </div>
      
    </div>
    <script type="text/javascript">
        /* https://stackoverflow.com/questions/3027707/how-to-change-the-playing-speed-of-videos-in-html5 */
        document.querySelector('video').defaultPlaybackRate = 1.0;
        document.querySelector('video').play();

        var videos =document.querySelectorAll('video');
        for (var i=0;i<1;i++)
        {
            videos[i].playbackRate = 1.0;
        }
    </script>
    <script>
        /* https://stackoverflow.com/questions/21163756/html5-and-javascript-to-play-videos-only-when-visible */
        var videos = document.getElementsByTagName("video");

        function checkScroll() {
            var fraction = 0.5; // Play when 70% of the player is visible.

            for(var i = 0; i < 1; i++) {  // only apply to the first video

                var video = videos[i];

                var x = video.offsetLeft, y = video.offsetTop, w = video.offsetWidth, h = video.offsetHeight, r = x + w, //right
                    b = y + h, //bottom
                    visibleX, visibleY, visible;

                visibleX = Math.max(0, Math.min(w, window.pageXOffset + window.innerWidth - x, r - window.pageXOffset));
                visibleY = Math.max(0, Math.min(h, window.pageYOffset + window.innerHeight - y, b - window.pageYOffset));

                visible = visibleX * visibleY / (w * h);

                if (visible > fraction) {
                    video.play();
                } else {
                    video.pause();
                }

            }

        }
        window.addEventListener('scroll', checkScroll, false);
        window.addEventListener('resize', checkScroll, false);
    </script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            // Function to check if the user is on a mobile device
            function isMobileDevice() {
                return /Mobi|Android/i.test(navigator.userAgent);
            }
            // If the user is on a mobile device, disable autoplay
            if (isMobileDevice()) {
                const videos = document.querySelectorAll('video');
                videos.forEach(video => {
                    video.autoplay = false;
                    video.controls = true;
                });
            }
        });
    </script>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=51e0d73d83d06baa7a00000f"
            type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
            crossorigin="anonymous"></script>
    <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"
            type="text/javascript"></script>
  </body>

</html>
